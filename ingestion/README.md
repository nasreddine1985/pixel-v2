# Payment Ingestion Service

Spring Boot Apache Camel application that orchestrates the payment message ingestion flow using various kamelets for comprehensive payment processing.

## Overview

The Payment Ingestion Service provides a unified entry point for payment messages from multiple channels and orchestrates their processing through validation, idempotence checking, and publishing to Kafka topics. The service now includes **comprehensive centralized logging** through the `k-log-tx` kamelet, providing complete observability and audit trail for all payment processing operations.

## Architecture

The ingestion service now supports **intelligent message routing** based on the source channel after duplicate prevention:

- **CFT messages** â†’ Continue to Kafka (existing batch processing)
- **HTTP/MQ messages** â†’ Route directly to processing module (real-time processing)

```
                              ğŸ”„ INTELLIGENT MESSAGE ROUTING ARCHITECTURE ğŸ”„
                          â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“¥ RECEPTION LAYER - Message Receipt Kamelets
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   k-mq-message-     â”‚    â”‚  k-http-message-    â”‚    â”‚   k-cft-data-       â”‚
â”‚      receiver       â”‚    â”‚      receiver       â”‚    â”‚      receiver       â”‚
â”‚                     â”‚    â”‚                     â”‚    â”‚                     â”‚
â”‚ ğŸ“¬ IBM MQ Queues    â”‚    â”‚ ğŸŒ HTTP/REST API    â”‚    â”‚ ğŸ“ File System      â”‚
â”‚ â€¢ Queue Monitoring  â”‚    â”‚ â€¢ POST /payments    â”‚    â”‚ â€¢ Directory Watch   â”‚
â”‚ â€¢ Connection Mgmt   â”‚    â”‚ â€¢ JSON Payloads     â”‚    â”‚ â€¢ XML File Parse    â”‚
â”‚ â€¢ Persistent Deliv. â”‚    â”‚ â€¢ CORS Support      â”‚    â”‚ â€¢ Line-by-line Proc â”‚
â”‚                     â”‚    â”‚                     â”‚    â”‚                     â”‚
â”‚ ReceiptChannel="MQ" â”‚    â”‚ ReceiptChannel="HTTP"â”‚   â”‚ ReceiptChannel="CFT"â”‚
â”‚ MessageSource=      â”‚    â”‚ MessageSource=       â”‚    â”‚ MessageSource=      â”‚
â”‚   "MQ_SERIES"       â”‚    â”‚   "HTTP_API"        â”‚    â”‚   "CFT_FILE"        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚                          â”‚                          â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                     â”‚
                       â•â•â•â•â•â•â•â•â•â•â•â•â•â–¼â•â•â•â•â•â•â•â•â•â•â•â•â•
                       ğŸ“‹ INGESTION ORCHESTRATOR
                       â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                       PaymentIngestionRouteBuilder
                                     â”‚
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    ğŸ”„ VERTICAL PROCESSING PIPELINE - All Messages Flow Through These Steps Sequentially
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                                     â”‚
                                     â–¼
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚        ğŸ“Š STEP 1           â”‚
                        â”‚    Database Persistence     â”‚
                        â”‚                             â”‚
                        â”‚        k-db-tx              â”‚
                        â”‚                             â”‚
                        â”‚    â€¢ Initial Message Save   â”‚
                        â”‚    â€¢ Transaction Mgmt       â”‚
                        â”‚    â€¢ Error Handling         â”‚
                        â”‚    â€¢ Status Headers         â”‚
                        â”‚    â€¢ k-log-tx Integration   â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                      â”‚
                                      â–¼
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚        ğŸ“Š STEP 2           â”‚
                        â”‚    Reference Enrichment     â”‚
                        â”‚                             â”‚
                        â”‚   k-referentiel-data-       â”‚
                        â”‚         loader              â”‚
                        â”‚                             â”‚
                        â”‚    â€¢ REST API Calls         â”‚
                        â”‚    â€¢ Config Data Load       â”‚
                        â”‚    â€¢ Header Enrichment      â”‚
                        â”‚    â€¢ Mapping Data           â”‚
                        â”‚    â€¢ k-log-tx Integration   â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                      â”‚
                                      â–¼
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚        ğŸ“Š STEP 3           â”‚
                        â”‚  Enriched Data Persistence  â”‚
                        â”‚                             â”‚
                        â”‚        k-db-tx              â”‚
                        â”‚                             â”‚
                        â”‚    â€¢ Enriched Data Save     â”‚
                        â”‚    â€¢ Audit Trail            â”‚
                        â”‚    â€¢ Status Tracking        â”‚
                        â”‚    â€¢ Reference Integration  â”‚
                        â”‚    â€¢ k-log-tx Integration   â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                      â”‚
                                      â–¼
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚        ğŸ“Š STEP 4           â”‚
                        â”‚    Message Validation       â”‚
                        â”‚                             â”‚
                        â”‚   k-ingestion-technical-    â”‚
                        â”‚        validation           â”‚
                        â”‚                             â”‚
                        â”‚    â€¢ Structure Validation   â”‚
                        â”‚    â€¢ Format Checking        â”‚
                        â”‚    â€¢ Compliance Rules       â”‚
                        â”‚    â€¢ Schema Verification    â”‚
                        â”‚    â€¢ k-log-tx Integration   â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                      â”‚
                                      â–¼
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚        ğŸ“Š STEP 5           â”‚
                        â”‚   Idempotence Checking      â”‚
                        â”‚                             â”‚
                        â”‚   k-payment-idempotence-    â”‚
                        â”‚          helper             â”‚
                        â”‚                             â”‚
                        â”‚    â€¢ Duplicate Detection    â”‚
                        â”‚    â€¢ InstrId Tracking       â”‚
                        â”‚    â€¢ Error/Warn Actions     â”‚
                        â”‚    â€¢ Uniqueness Validation  â”‚
                        â”‚    â€¢ k-log-tx Integration   â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                      â”‚
                                      â–¼
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚        ğŸ“Š STEP 6           â”‚
                        â”‚   Smart Routing Decision    â”‚
                        â”‚                             â”‚
                        â”‚      Routing Engine         â”‚
                        â”‚     (Channel Based)         â”‚
                        â”‚                             â”‚
                        â”‚    â€¢ Channel Detection      â”‚
                        â”‚    â€¢ Route Selection        â”‚
                        â”‚    â€¢ Performance Opt        â”‚
                        â”‚    â€¢ Decision Logic         â”‚
                        â”‚    â€¢ k-log-tx Integration   â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                      â”‚
                        â•â•â•â•â•â•â•â•â•â•â•â•â–¼â•â•â•â•â•â•â•â•â•â•â•â•
                        ğŸš€ INTELLIGENT ROUTING ğŸš€
                        â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                        if (ReceiptChannel == "CFT")
                                    â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚                     â”‚                     â”‚
              â–¼                     â–¼                     â–¼
    ğŸ­ BATCH PROCESSING     âš¡ REAL-TIME PROCESSING     âŒ REJECTION PATH
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•       â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•       â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    CFT Messages            HTTP/MQ Messages           Invalid Messages
              â”‚                     â”‚                     â”‚
              â–¼                     â–¼                     â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ direct:kafka-   â”‚    â”‚ direct:         â”‚    â”‚ direct:         â”‚
   â”‚ publisher       â”‚    â”‚ processing-     â”‚    â”‚ rejection-      â”‚
   â”‚                 â”‚    â”‚ publisher       â”‚    â”‚ handler         â”‚
   â”‚ Route to:       â”‚    â”‚                 â”‚    â”‚                 â”‚
   â”‚ â€¢ pacs.008 â†’    â”‚    â”‚ Route to:       â”‚    â”‚ Route to:       â”‚
   â”‚   kafka topic   â”‚    â”‚ â€¢ Processing    â”‚    â”‚ â€¢ Dead Letter   â”‚
   â”‚ â€¢ pan.001 â†’     â”‚    â”‚   Module via    â”‚    â”‚   Topics        â”‚
   â”‚   kafka topic   â”‚    â”‚ â€¢ direct:kafka- â”‚    â”‚ â€¢ Error Logs    â”‚
   â”‚ â€¢ default â†’     â”‚    â”‚   message-      â”‚    â”‚ â€¢ Monitoring    â”‚
   â”‚   kafka topic   â”‚    â”‚   processing    â”‚    â”‚                 â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚                      â”‚
             â–¼                      â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ Apache Kafka    â”‚    â”‚ Processing      â”‚
   â”‚ Topics          â”‚    â”‚ Module          â”‚
   â”‚                 â”‚    â”‚ (Spring Boot)   â”‚
   â”‚ â€¢ payments-     â”‚    â”‚                 â”‚
   â”‚   pacs008       â”‚    â”‚ â€¢ Message Type  â”‚
   â”‚ â€¢ payments-     â”‚    â”‚   Detection     â”‚
   â”‚   pan001        â”‚    â”‚ â€¢ Dynamic Route â”‚
   â”‚ â€¢ payments-     â”‚    â”‚ â€¢ CDM Transform â”‚
   â”‚   default       â”‚    â”‚ â€¢ Real-time Procâ”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚                      â”‚
             â”‚                      â–¼
             â”‚            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
             â”‚            â”‚ Processing      â”‚
             â”‚            â”‚ Module          â”‚
             â”‚            â”‚                 â”‚
             â”‚            â”‚ â€¢ Message Type  â”‚
             â”‚            â”‚   Detection     â”‚
             â”‚            â”‚ â€¢ CDM Transform â”‚
             â”‚            â”‚ â€¢ CDM Persist   â”‚
             â”‚            â”‚   (via k-db-tx) â”‚
             â”‚            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ k-kafka-        â”‚
   â”‚ message-        â”‚
   â”‚ receiver        â”‚
   â”‚                 â”‚
   â”‚ â€¢ Multi-topic   â”‚
   â”‚   Consumer      â”‚
   â”‚ â€¢ Deserialize   â”‚
   â”‚ â€¢ Route to      â”‚
   â”‚   Processing    â”‚
   â”‚   Module        â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ Processing      â”‚
   â”‚ Module          â”‚
   â”‚ (Unified)       â”‚
   â”‚                 â”‚
   â”‚ Handles both:   â”‚
   â”‚ â€¢ Batch (Kafka) â”‚
   â”‚ â€¢ Real-time     â”‚
   â”‚   (Direct)      â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸ”§ SUPPORTING KAMELETS & COMPONENTS:
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
â€¢ k-db-tx: Unified persistence (initial + enriched + CDM)
â€¢ k-referentiel-data-loader: REST API data enrichment
â€¢ k-ingestion-technical-validation: Message structure validation
â€¢ k-payment-idempotence-helper: Duplicate prevention & tracking
â€¢ k-kafka-message-receiver: Kafka topic consumer & routing
â€¢ k-log-tx: Centralized logging with database persistence & audit trail
â€¢ MessageMetadataEnrichmentProcessor: Processing module integration

ğŸ—‚ï¸ CENTRALIZED LOGGING ARCHITECTURE:
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚       ğŸ“‹ k-log-tx          â”‚
                    â”‚    Centralized Logging      â”‚
                    â”‚                             â”‚
                    â”‚    â€¢ Structured Metadata    â”‚
                    â”‚    â€¢ Correlation Tracking   â”‚
                    â”‚    â€¢ Database Persistence   â”‚
                    â”‚    â€¢ Business/Route/Error   â”‚
                    â”‚      Category Classificationâ”‚
                    â”‚    â€¢ Async/Sync Processing  â”‚
                    â”‚    â€¢ Complete Audit Trail   â”‚
                    â”‚                             â”‚
                    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
                    â”‚  â”‚    LogEntry Entity      â”‚ â”‚
                    â”‚  â”‚                         â”‚ â”‚
                    â”‚  â”‚  â€¢ log_level (INFO/WARN/â”‚ â”‚
                    â”‚  â”‚    ERROR)               â”‚ â”‚
                    â”‚  â”‚  â€¢ log_source (componentâ”‚ â”‚
                    â”‚  â”‚  â€¢ log_category         â”‚ â”‚
                    â”‚  â”‚  â€¢ correlation_id       â”‚ â”‚
                    â”‚  â”‚  â€¢ message_body         â”‚ â”‚
                    â”‚  â”‚  â€¢ metadata (JSON)      â”‚ â”‚
                    â”‚  â”‚  â€¢ created_at           â”‚ â”‚
                    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â–²     â–²     â–²     â–²
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚     â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚                       â”‚     â”‚                       â”‚
    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”            â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”â”‚                  â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”
    â”‚Receipt  â”‚            â”‚Database â”‚â”‚                  â”‚Routing  â”‚
    â”‚Kamelets â”‚            â”‚k-db-tx  â”‚â”‚                  â”‚Decision â”‚
    â”‚Logging  â”‚            â”‚Logging  â”‚â”‚                  â”‚Logging  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                      â”‚
                               â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”
                               â”‚Validation â”‚
                               â”‚& Business â”‚
                               â”‚Process    â”‚
                               â”‚Logging    â”‚
                               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸ“Š PERFORMANCE METRICS & OBSERVABILITY:
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
â€¢ HTTP/MQ Route: 50-70% latency reduction (bypasses Kafka)
â€¢ CFT Route: High throughput batch processing (via Kafka)
â€¢ Dual Processing: Optimized for channel characteristics
â€¢ Error Handling: Comprehensive monitoring & dead letter queues
â€¢ Centralized Logging: Complete audit trail with correlation tracking
â€¢ Log Performance: Async processing for minimal impact on message flow
â€¢ Observability: 36+ enhanced log points for complete visibility
â€¢ Audit Compliance: Database-persisted logs for regulatory requirements
```

## Processing Flow

### 1. Message Receipt

The ingestion service supports three different message receipt channels, each handled by specialized kamelets:

- **MQ Series**: `k-mq-message-receiver` monitors IBM MQ queues for incoming payment messages

  - Connects to specified queue managers and channels
  - Provides persistent message delivery guarantees
  - Sets MQ-specific metadata headers for tracking

- **REST API**: `k-http-message-receiver` exposes HTTP endpoints for direct message submission

  - Accepts JSON payloads with message type and XML content
  - Provides immediate HTTP response confirmation
  - Supports CORS and content negotiation

- **File Processing**: `k-cft-data-receiver` monitors file system directories for XML payment files
  - Watches NAS folders for new files matching patterns
  - Processes large files line-by-line for memory efficiency
  - Handles file lifecycle (incoming â†’ processed/error directories)

All receiver kamelets focus solely on message receipt, logging, and routing - they do not perform persistence operations. They set comprehensive metadata headers that are used throughout the processing pipeline. **NEW**: All log statements are now enhanced with centralized logging via `k-log-tx` kamelet for complete audit trail.

### 2. Database Persistence (First Step)

- Uses `k-db-tx` kamelet immediately after message receipt
- Persists all received messages to Oracle database with unified data model
- **NEW**: Supports both standard MESSAGE persistence and CDM (Common Data Model) objects
- Handles transaction management and error scenarios
- Sets persistence status headers for downstream processing
- **NEW**: All persistence operations are logged via `k-log-tx` with success/failure tracking

#### CDM Support Features

- **Dual Entity Support**: Can persist both `ReceivedMessage` and `CdmMessage` entities
- **JSON Payload Processing**: Automatically parses CDM JSON payloads to extract metadata
- **Smart Routing**: Automatically detects message type (MESSAGE vs CDM) based on payload content
- **Comprehensive Audit Trail**: Tracks CDM transformations and relationships to original messages

### 3. Reference Data Enrichment

- Uses `k-referentiel-data-loader` kamelet to call reference APIs
- Enriches message headers with configuration and mapping data
- **NEW**: Enrichment start and completion are logged via `k-log-tx` for traceability

### 4. Enriched Data Persistence (Second Database Save)

- Uses `k-db-tx` kamelet again after reference enrichment
- Persists the enriched message data including reference information loaded
- **Enhanced**: Supports both MESSAGE and CDM entity updates with enriched data
- Updates the database record with additional reference data and metadata
- Provides audit trail for enrichment process
- Sets enriched data persistence status headers for downstream processing
- **NEW**: Enriched persistence operations are logged via `k-log-tx` with comprehensive context

#### CDM Enrichment Features

- **Dynamic Field Mapping**: Automatically extracts and maps CDM fields from JSON payload
- **Metadata Preservation**: Maintains CDM-specific metadata during enrichment process
- **Relationship Tracking**: Links enriched CDM objects to their original message sources

### 5. Message Validation

- Uses `k-ingestion-technical-validation` kamelet for comprehensive validation
- Checks message structure, format, and compliance
- Supports both strict and lenient validation modes
- **NEW**: Validation success and failure are logged via `k-log-tx` with detailed error information

### 6. Idempotence Checking

- Uses `k-payment-idempotence-helper` kamelet to prevent duplicate processing
- Tracks unique identifiers (InstrId, EndToEndId, MsgId)
- Configurable duplicate handling (ERROR, IGNORE, WARN)
- **NEW**: All idempotence operations logged via `k-log-tx` including duplicate detection and warnings

### 7. Intelligent Message Routing

The ingestion service implements **smart routing** based on the source channel identified during message receipt:

#### CFT Messages (File-based)

- **Route**: Continue to Kafka topics (existing behavior)
- **Purpose**: Batch processing optimization
- **Topics**: `payments-pacs008`, `payments-pan001`, `payments-default`
- **Downstream**: Consumed by `k-kafka-message-receiver` â†’ processing module

#### HTTP/MQ Messages (Interactive channels)

- **Route**: Direct to processing module via `direct:kafka-message-processing`
- **Purpose**: Real-time processing with reduced latency
- **Benefits**: Bypasses Kafka for faster response times
- **Downstream**: Direct integration with processing module

#### Routing Logic

```java
// After idempotence check and validation
.choice()
    .when(header("CanProcess").isEqualTo(true))
        .choice()
            .when(header("ReceiptChannel").isEqualTo("CFT"))
                .to("direct:kafka-publisher")      // CFT â†’ Kafka
            .otherwise()
                .to("direct:processing-publisher") // HTTP/MQ â†’ Processing
        .endChoice()
    .otherwise()
        .to("direct:rejection-handler")           // Invalid messages
.end();
```

#### Error Handling

- Routes rejected messages to dead letter topics
- Handles system errors with comprehensive error logging
- Maintains same error handling for both routing paths
- **NEW**: All error conditions are logged via `k-log-tx` with ERROR level categorization and detailed context

````

## Configuration

### Application Properties

#### Server Configuration

```properties
server.port=8080
server.servlet.context-path=/ingestion
````

#### MQ Series Configuration

```properties
ingestion.mq.input.queue=PAYMENT_INPUT
ingestion.mq.host=localhost
ingestion.mq.port=1414
ingestion.mq.queue.manager=QM1
ingestion.mq.channel=DEV.ADMIN.SVRCONN
```

#### File Processing Configuration

```properties
ingestion.file.input.directory=/tmp/payments-in
ingestion.file.processed.directory=/tmp/payments-processed
ingestion.file.pattern=*.xml
```

#### Kafka Configuration

```properties
ingestion.kafka.brokers=localhost:9092
ingestion.kafka.topic.default=payments-processed
ingestion.kafka.topic.pacs008=payments-pacs008
ingestion.kafka.topic.pan001=payments-pan001
ingestion.kafka.topic.rejected=payments-rejected
ingestion.kafka.topic.errors=payments-errors
```

#### Processing Module Integration

```properties
# Processing Module Integration
# CFT messages go to Kafka (existing process)
# HTTP/MQ messages go directly to processing module
ingestion.processing.endpoint=direct:kafka-message-processing
ingestion.processing.enabled=true
```

#### Database Configuration (for k-db-tx kamelet)

```properties
# Database connection settings
spring.datasource.url=jdbc:oracle:thin:@//localhost:1521/xe
spring.datasource.username=pixel_user
spring.datasource.password=pixel_pass
spring.jpa.database-platform=org.hibernate.dialect.Oracle12cDialect
spring.jpa.hibernate.ddl-auto=validate

# CDM Processing Configuration
persistence.cdm.enabled=true
persistence.cdm.auto-extract-fields=true
persistence.cdm.json-validation.enabled=true

# Centralized Logging Configuration (for k-log-tx kamelet)
logging.centralized.enabled=true
logging.centralized.async.enabled=true
logging.centralized.correlation.header=MessageId
logging.level.k-log-tx=INFO

# Database connection for centralized logging
logging.datasource.url=jdbc:oracle:thin:@//localhost:1521/xe
logging.datasource.username=pixel_log_user
logging.datasource.password=pixel_log_pass

# Persistence Configuration (for k-db-tx)
persistence.transaction.timeout=30000
persistence.retry.max-attempts=3
persistence.retry.delay=1000
```

````

### Environment-Specific Profiles- **Development**: `application-dev.properties` - Lenient validation, local services

- **Production**: `application-prod.properties` - Strict validation, environment variables
- **Test**: `application-test.properties` - Mock services, in-memory storage

## API Endpoints

### Payment Submission

```http
POST /ingestion/api/v1/payments
Content-Type: application/json

{
  "messageType": "pacs.008",
  "payload": "<?xml version='1.0'?>..."
}
````

### Health Check

```http
GET /ingestion/health
```

### Metrics

```http
GET /ingestion/metrics
```

## Message Flow Examples

### Successful MQ Processing (Updated Flow)

```yaml
# MQ Message Reception & Processing - NEW: Direct to Processing Module + Centralized Logging
- Receipt: k-mq-message-receiver â†’ Log message, set MQ metadata headers (ReceiptChannel: "MQ") + k-log-tx logging
- Route: Ingestion Orchestrator â†’ Direct to persistence pipeline + k-log-tx start logging
- Persist: k-db-tx â†’ Initial database storage with transaction management + k-log-tx success/failure logging
- Enrich: k-referentiel-data-loader â†’ Add reference data headers + k-log-tx start/completion logging
- Persist Enriched: k-db-tx â†’ Save enriched data to database + k-log-tx enrichment persistence logging
- Validate: k-ingestion-technical-validation â†’ Check message structure + k-log-tx validation logging
- Dedupe: k-payment-idempotence-helper â†’ Verify uniqueness + k-log-tx idempotence logging
- Smart Route: Intelligent Routing â†’ ReceiptChannel = "MQ" â†’ direct:processing-publisher + k-log-tx routing decision logging
- Publish: Processing Module â†’ direct:kafka-message-processing (Real-time processing) + k-log-tx publishing logging
- Transform: Processing Module â†’ Message to CDM transformation (if applicable)
- CDM Persist: Processing Module handles CDM persistence internally
```

### Successful HTTP API Processing (Updated Flow)

```yaml
# REST API Message Reception & Processing - NEW: Direct to Processing Module + Centralized Logging
- Receipt: k-http-message-receiver â†’ Log request, set HTTP metadata headers (ReceiptChannel: "HTTP"), return receipt confirmation + k-log-tx logging
- Route: Ingestion Orchestrator â†’ Direct to persistence pipeline + k-log-tx start logging
- Persist: k-db-tx â†’ Initial database storage with transaction management + k-log-tx success/failure logging
- Enrich: k-referentiel-data-loader â†’ Add reference data headers + k-log-tx start/completion logging
- Persist Enriched: k-db-tx â†’ Save enriched data to database + k-log-tx enrichment persistence logging
- Validate: k-ingestion-technical-validation â†’ Check message structure + k-log-tx validation logging
- Dedupe: k-payment-idempotence-helper â†’ Verify uniqueness + k-log-tx idempotence logging
- Smart Route: Intelligent Routing â†’ ReceiptChannel = "HTTP" â†’ direct:processing-publisher + k-log-tx routing decision logging
- Publish: Processing Module â†’ direct:kafka-message-processing (Real-time processing) + k-log-tx publishing logging
- Transform: Processing Module â†’ Message to CDM transformation (if applicable)
- CDM Persist: Processing Module handles CDM persistence internally
```

### Successful File Processing (Unchanged - Kafka Flow)

```yaml
# File CFT Message Reception & Processing - UNCHANGED: Continues to Kafka + Enhanced Logging
- Receipt: k-cft-data-receiver â†’ Monitor directory, process file line-by-line, set file metadata headers (ReceiptChannel: "CFT") + k-log-tx logging
- Route: Ingestion Orchestrator â†’ Direct to persistence pipeline + k-log-tx start logging
- Persist: k-db-tx â†’ Initial database storage with transaction management + k-log-tx success/failure logging
- Enrich: k-referentiel-data-loader â†’ Add reference data headers + k-log-tx start/completion logging
- Persist Enriched: k-db-tx â†’ Save enriched data to database + k-log-tx enrichment persistence logging
- Validate: k-ingestion-technical-validation â†’ Check message structure + k-log-tx validation logging
- Dedupe: k-payment-idempotence-helper â†’ Verify uniqueness + k-log-tx idempotence logging
- Smart Route: Intelligent Routing â†’ ReceiptChannel = "CFT" â†’ direct:kafka-publisher + k-log-tx routing decision logging
- Publish: Kafka Topic â†’ payments-pacs008 (Batch processing optimization) + k-log-tx publishing logging
- Downstream: k-kafka-message-receiver â†’ Processing Module
```

### Validation Failure

```yaml
# Failed Validation Flow (Any Channel) + Enhanced Error Logging
- Receipt: [k-mq/http/cft]-message-receiver â†’ Log and set channel-specific metadata + k-log-tx logging
- Route: Ingestion Orchestrator â†’ Direct to persistence pipeline + k-log-tx start logging
- Persist: k-db-tx â†’ Initial database storage with transaction management + k-log-tx success/failure logging
- Enrich: k-referentiel-data-loader â†’ Add reference data headers + k-log-tx start/completion logging
- Persist Enriched: k-db-tx â†’ Save enriched data to database + k-log-tx enrichment persistence logging
- Validate: k-ingestion-technical-validation â†’ Validation fails + k-log-tx ERROR level logging with validation details
- Reject: Kafka Topic â†’ payments-rejected + k-log-tx rejection logging
```

### Database Persistence Failure

```yaml
# Initial Database Failure Flow (Any Channel) + Enhanced Error Logging
- Receipt: [k-mq/http/cft]-message-receiver â†’ Log and set channel-specific metadata + k-log-tx logging
- Route: Ingestion Orchestrator â†’ Direct to persistence pipeline + k-log-tx start logging
- Persist: k-db-tx â†’ Initial database failure + k-log-tx ERROR level logging with exception details
- Error: Route to error handler â†’ payments-errors topic + k-log-tx error handling logging
```

### Enriched Data Persistence Failure

```yaml
# Enriched Data Persistence Failure Flow (Any Channel) + Enhanced Error Logging
- Receipt: [k-mq/http/cft]-message-receiver â†’ Log and set channel-specific metadata + k-log-tx logging
- Route: Ingestion Orchestrator â†’ Direct to persistence pipeline + k-log-tx start logging
- Persist: k-db-tx â†’ Initial database storage with transaction management + k-log-tx success logging
- Enrich: k-referentiel-data-loader â†’ Add reference data headers + k-log-tx start/completion logging
- Persist Enriched: k-db-tx â†’ Enriched data persistence failure + k-log-tx ERROR level logging with exception details
- Error: Route to error handler â†’ payments-errors topic + k-log-tx error handling logging
```

## Message Format

### Standard MESSAGE Entity Processing

The kamelet supports two processing modes based on message content:

- **MESSAGE Mode**: Traditional XML payment message processing
- **CDM Mode**: Common Data Model JSON object processing

### Enriched Message (Success)

#### Kafka Route (CFT Messages)

```json
{
  "metadata": {
    "receiptChannel": "CFT",
    "receiptTimestamp": "2025-10-21 10:30:00",
    "ingestionStartTime": "2025-10-21 10:30:00",
    "publishTimestamp": "2025-10-21 10:30:05",
    "primaryIdentifier": "INSTR123456",
    "messageType": "pacs.008",
    "validationPassed": true,
    "duplicateCheck": true,
    "routingDestination": "kafka"
  },
  "payload": "<?xml version='1.0'?>..."
}
```

#### Processing Module Route (HTTP/MQ Messages)

```json
{
  "metadata": {
    "receiptChannel": "HTTP",
    "receiptTimestamp": "2025-10-21 10:30:00",
    "ingestionStartTime": "2025-10-21 10:30:00",
    "publishTimestamp": "2025-10-21 10:30:02",
    "primaryIdentifier": "INSTR123456",
    "messageType": "pacs.008",
    "validationPassed": true,
    "duplicateCheck": true,
    "routingDestination": "processing"
  },
  "payload": "<?xml version='1.0'?>..."
}
```

### CDM Message Processing

#### CDM Input Format (JSON Payload)

```json
{
  "cdmType": "PAYMENT_INSTRUCTION",
  "instructionId": "PI-2025-001",
  "endToEndId": "E2E-2025-001",
  "amount": {
    "value": "1000.00",
    "currency": "EUR"
  },
  "debtor": {
    "name": "John Doe",
    "account": "FR1420041010050500013M02606"
  },
  "creditor": {
    "name": "Jane Smith",
    "account": "DE89370400440532013000"
  },
  "remittanceInfo": "Invoice payment",
  "executionDate": "2025-10-21"
}
```

#### CDM Processing Output (After Transformation)

```json
{
  "metadata": {
    "receiptChannel": "HTTP",
    "receiptTimestamp": "2025-10-21 10:30:00",
    "entityType": "CDM",
    "cdmType": "PAYMENT_INSTRUCTION",
    "instructionId": "PI-2025-001",
    "processingMode": "CDM_ENTITY",
    "validationPassed": true,
    "routingDestination": "processing",
    "transformationStatus": "COMPLETED",
    "cdmPersistenceRequired": true
  },
  "cdmPayload": {
    // Transformed CDM JSON payload ready for persistence
  }
}
```

#### ğŸ†• CDM Transformation and Persistence Flow

After the processing module transforms payment messages to CDM objects, the system automatically persists these CDM objects using the `k-db-tx` kamelet:

````yaml
# CDM Post-Processing Flow (HTTP/MQ Messages) - Handled by Processing Module
- Processing Module: Transform payment message to CDM format
- Processing Module: Internally routes CDM to k-db-tx
- Processing Module: Saves CDM objects to CdmMessage entity
- Processing Module: Links CDM records to original payment messages
- Processing Module: Updates processing status and CDM references
```**Key Features:**

- **Clear Responsibility Separation**: Ingestion handles initial persistence, Processing Module handles CDM transformation and persistence
- **Dual Persistence**: Original message (ingestion) + transformed CDM object (processing module) stored separately
- **Relationship Tracking**: Processing module links CDM records to source payment messages via foreign keys
- **Transaction Management**: Processing module ensures consistency for CDM persistence
- **Error Isolation**: CDM persistence failures in processing module don't affect ingestion message processing

### Rejection Message

```json
{
  "rejectionInfo": {
    "reason": "VALIDATION_FAILED",
    "timestamp": "2023-10-19 10:30:02",
    "receiptChannel": "REST_API",
    "originalMessageId": "MSG123",
    "errorDetails": "Missing required field: InstrId"
  },
  "originalMessage": "<?xml version='1.0'?>..."
}
````

## New Features: Intelligent Message Routing

### ğŸ†• Smart Routing Engine

The ingestion service now implements **intelligent message routing** that optimizes processing based on the source channel:

#### Architecture Benefits

- **Real-time Processing**: HTTP/MQ messages get immediate processing through direct routing
- **Batch Optimization**: CFT messages maintain Kafka-based flow for efficient batch processing
- **Backward Compatibility**: All existing CFT processes preserved without changes
- **Reduced Latency**: Interactive channels bypass Kafka queuing for faster response

## ğŸ†• Centralized Logging with k-log-tx

### Overview

The ingestion service now includes **comprehensive centralized logging** through the `k-log-tx` kamelet, providing complete observability and audit trail for all payment processing operations.

### Key Features

#### Complete Audit Trail

- **Every log statement** in the ingestion routes is enhanced with centralized logging
- All log events are persisted to database via `k-log-tx` kamelet
- Structured metadata for advanced querying and analysis
- End-to-end correlation tracking using MessageId

#### Categorized Logging

- **Business Level**: Core business operations (INFO)
- **Route Level**: Technical routing decisions (INFO)
- **Error Level**: Validation failures, system errors (ERROR/WARN)

#### Structured Metadata

```yaml
LogLevel: "INFO|WARN|ERROR"
LogSource: "ORCHESTRATOR|MQ_RECEIPT|HTTP_RECEIPT|CFT_RECEIPT|DATABASE_PERSISTER|etc."
LogCategory: "BUSINESS|ROUTE|ERROR"
CorrelationId: "${header.MessageId}"
```

#### Enhanced Observability

- **36+ log statements** enhanced with k-log-tx integration
- Complete visibility into payment processing flow
- Performance monitoring through structured log data
- Error pattern analysis and troubleshooting support

### Integration Benefits

#### Operational Intelligence

- **Performance Monitoring**: Track processing stages and latencies
- **Error Analysis**: Categorized error tracking with correlation
- **Business Metrics**: Extract business intelligence from structured logs
- **Compliance**: Complete audit trail for regulatory requirements

#### Real-time Monitoring

- **Correlation Tracking**: Follow messages end-to-end using MessageId
- **Component Visibility**: Track performance of individual kamelets
- **Route Analysis**: Compare performance between Kafka and direct routes
- **Error Alerting**: Set up alerts based on error categories and patterns

#### Routing Decision Matrix

| Source Channel | Receipt Header           | Routing Destination                               | Processing Type  | Latency  |
| -------------- | ------------------------ | ------------------------------------------------- | ---------------- | -------- |
| **CFT Files**  | `ReceiptChannel: "CFT"`  | `direct:kafka-publisher` â†’ Kafka Topics           | Batch Processing | Standard |
| **HTTP API**   | `ReceiptChannel: "HTTP"` | `direct:processing-publisher` â†’ Processing Module | Real-time        | Reduced  |
| **MQ Series**  | `ReceiptChannel: "MQ"`   | `direct:processing-publisher` â†’ Processing Module | Real-time        | Reduced  |

#### Configuration Options

```properties
# Enable/disable intelligent routing
ingestion.processing.enabled=true

# Configure processing module endpoint
ingestion.processing.endpoint=direct:kafka-message-processing

# Route logging (debug purposes)
logging.level.com.pixel.v2.ingestion=DEBUG
```

### ğŸ”„ Integration Architecture

#### Complete Flow Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ HTTP/MQ     â”‚    â”‚ CFT Files   â”‚    â”‚ Rejected    â”‚
â”‚ Messages    â”‚    â”‚ Messages    â”‚    â”‚ Messages    â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚                  â”‚                  â”‚
       â–¼                  â–¼                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Processing  â”‚    â”‚ Kafka       â”‚    â”‚ Dead Letter â”‚
â”‚ Module      â”‚    â”‚ Topics      â”‚    â”‚ Topics      â”‚
â”‚ (Real-time) â”‚    â”‚ (Batch)     â”‚    â”‚ (Errors)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                  â”‚
       â”‚                  â–¼
       â”‚           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚           â”‚ k-kafka-    â”‚
       â”‚           â”‚ message-    â”‚
       â”‚           â”‚ receiver    â”‚
       â”‚           â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚                  â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                          â–¼                  â”‚
                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
                  â”‚ Processing  â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚ Module      â”‚
                  â”‚ (Unified)   â”‚
                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Monitoring

### Health Checks

- Application health: `/health`
- Camel routes health via Spring Boot Actuator
- Kafka connectivity monitoring
- Processing module integration health

### Metrics

- Message throughput per channel (MQ, HTTP, CFT)
- Routing decision metrics (Kafka vs Processing)
- Validation success/failure rates
- Duplicate detection statistics
- Processing latency metrics by route
- **NEW**: Real-time processing performance metrics

### Logging

- Structured logging with correlation IDs
- Processing stage tracking
- **NEW**: Routing decision logging with channel identification
- Error categorization and alerting
- **NEW**: Performance tracking for route comparison
- **NEW**: Centralized logging via `k-log-tx` kamelet with database persistence
- **NEW**: Complete audit trail with business/technical/error categorization
- **NEW**: Correlation tracking using MessageId for end-to-end traceability

## Running the Application

### Local Development

```bash
# Start the application
mvn spring-boot:run

# With specific profile
mvn spring-boot:run -Dspring-boot.run.profiles=dev
```

### Docker Deployment

```bash
# Build Docker image
mvn clean package
docker build -t pixel-v2/ingestion .

# Run container
docker run -p 8080:8080 \
  -e SPRING_PROFILES_ACTIVE=prod \
  -e KAFKA_BROKERS=kafka:9092 \
  pixel-v2/ingestion
```

### Production Deployment

```bash
# Using environment variables
export KAFKA_BROKERS=kafka-cluster:9092
export MQ_HOST=mq-server
export VALIDATION_STRICT=true
java -jar ingestion-1.0.1-SNAPSHOT.jar
```

## Testing

### Unit Tests

```bash
mvn test
```

### Integration Tests

```bash
mvn verify
```

### Manual Testing

#### Standard MESSAGE Testing

```bash
# Send test XML message via API
curl -X POST http://localhost:8080/ingestion/api/v1/payments \
  -H "Content-Type: application/json" \
  -d '{"messageType":"pacs.008","payload":"<xml>test</xml>"}'
```

#### ğŸ†• CDM Message Testing

```bash
# Send test CDM JSON message via API (triggers transformation and CDM persistence)
curl -X POST http://localhost:8080/ingestion/api/v1/payments \
  -H "Content-Type: application/json" \
  -d '{
    "messageType": "CDM",
    "payload": "{\"cdmType\":\"PAYMENT_INSTRUCTION\",\"instructionId\":\"PI-TEST-001\",\"amount\":{\"value\":\"100.00\",\"currency\":\"EUR\"}}"
  }'

# Monitor CDM processing in processing module logs
tail -f logs/processing.log | grep "CDM-PERSISTENCE"

# Check CDM persistence in database
# This should show both original message and transformed CDM object
```

#### Health and Status Checks

```bash
# Check application health
curl http://localhost:8080/ingestion/health

# Check CDM processing metrics
curl http://localhost:8080/ingestion/metrics | grep cdm
```

## Message Receiver Kamelets

The ingestion service leverages three specialized kamelets for message receipt from different channels:

### k-mq-message-receiver

**Purpose**: Receives payment messages from IBM MQ queues

**Features**:

- Connects to IBM MQ using configurable connection parameters
- Monitors specified queues for incoming messages
- Enhanced logging with `[MQ-RECEIVER]` prefix for traceability
- Sets comprehensive metadata headers for downstream processing

**Configuration**:

```yaml
queueName: "PAYMENT_INPUT"
host: "localhost"
port: 1414
queueManager: "QM1"
channel: "DEV.ADMIN.SVRCONN"
username: "admin"
password: "admin"
```

**Metadata Headers Set**:

- `messageSource`: "MQ_SERIES"
- `receiptTimestamp`: Current timestamp
- `receiptChannel`: "MQ_QUEUE"
- `mqQueue`: Queue name being monitored

### k-http-message-receiver

**Purpose**: Receives payment messages via REST API endpoints

**Features**:

- Exposes HTTP endpoints for payment message submission
- Handles JSON payloads with message type and XML payload
- Enhanced logging with `[HTTP-RECEIVER]` prefix for request tracking
- Returns routing confirmation responses
- Supports content negotiation and proper HTTP status codes

**Configuration**:

```yaml
port: 8080
contextPath: "/api/v1/payments"
enableCors: true
maxRequestSize: "10MB"
```

**Metadata Headers Set**:

- `messageSource`: "HTTP_API"
- `receiptTimestamp`: Current timestamp
- `receiptChannel`: "REST_API"
- `apiPath`: Request path
- `httpMethod`: HTTP method used

**Response Format**:

```json
{
  "status": "RECEIVED",
  "message": "Payment message received and routed for processing",
  "receiptTimestamp": "2025-10-21 10:30:00.123"
}
```

### k-cft-data-receiver

**Purpose**: Monitors file system directories for XML payment files

**Features**:

- Monitors NAS/file system directories for new XML files
- Processes files line by line for large file handling
- Enhanced logging with `[CFT-RECEIVER]` prefix for file tracking
- Configurable file patterns and processing directories
- Automatic file movement to processed/error directories

**Configuration**:

```yaml
directoryPath: "/nas/incoming"
filePattern: ".*\\.xml"
processedDirectory: "/nas/processed"
errorDirectory: "/nas/error"
delay: 5000
```

**Metadata Headers Set**:

- `messageSource`: "CFT_FILE"
- `receiptTimestamp`: Current timestamp
- `receiptChannel`: "FILE_CFT"
- `fileName`: Original file name
- `lineNumber`: Current line being processed
- `directoryPath`: Source directory path

**File Processing Features**:

- Read lock mechanism to ensure file completion
- Streaming split processing for memory efficiency
- Empty line filtering
- Comprehensive error handling with file movement

## Dependencies

### Required Kamelets

- `k-mq-message-receiver`: MQ message receipt and logging
- `k-http-message-receiver`: HTTP API message receipt and logging
- `k-cft-data-receiver`: File system message receipt and logging
- `k-db-tx`: Unified database persistence
- `k-referentiel-data-loader`: Reference data enrichment
- `k-ingestion-technical-validation`: Message validation
- `k-payment-idempotence-helper`: Duplicate prevention
- `k-kafka-message-receiver`: **Kafka consumer for CFT message processing**
- `k-log-tx`: **NEW**: Centralized logging with database persistence and audit trail

### External Services

- **IBM MQ**: Message queue system
- **Kafka**: Event streaming platform (for CFT batch processing)
- **Reference API**: Configuration and mapping service
- **ğŸ†• Processing Module**: Real-time message processing service with endpoint `direct:kafka-message-processing`

### Integration Dependencies

#### For CFT Messages (Kafka Route)

- Kafka brokers must be available
- Topics must exist: `payments-pacs008`, `payments-pan001`, `payments-default`
- `k-kafka-message-receiver` must consume from these topics
- Processing module must be available as downstream consumer

#### For HTTP/MQ Messages (Direct Route)

- **ğŸ†• Processing module must be deployed and running**
- **ğŸ†• Endpoint `direct:kafka-message-processing` must be available**
- **ğŸ†• Processing module must handle message type detection and routing**
- **ğŸ†• Processing Module must handle CDM persistence internally**
- No Kafka dependency for real-time processing path

#### For CDM Persistence (Post-Processing)

- **ğŸ†• `k-db-tx` kamelet must be available for CDM persistence**
- **ğŸ†• `CdmMessage` entity and database table must be configured**
- **ğŸ†• Processing module must set `cdmPersistenceRequired=true` for CDM objects**
- **ğŸ†• CDM output endpoint `direct:cdm-persistence` must be configured**

### Deployment Requirements

#### Prerequisites Checklist

- [ ] **Processing Module**: Deployed with `direct:kafka-message-processing` endpoint

- [ ] **Kafka Cluster**: Available for CFT message batch processing
- [ ] **Database**: Oracle DB for persistence operations and centralized logging
- [ ] **Reference API**: Available for data enrichment
- [ ] **IBM MQ**: Connected for MQ message reception
- [ ] **k-log-tx Kamelet**: Deployed and configured for centralized logging

#### Environment Configuration

```bash
# Processing Module Integration
export INGESTION_PROCESSING_ENABLED=true
export INGESTION_PROCESSING_ENDPOINT=direct:kafka-message-processing

# Legacy Kafka Support (for CFT)
export KAFKA_BROKERS=kafka-cluster:9092
export KAFKA_TOPICS_PREFIX=payments-

# Database and Reference Services
export DB_URL=jdbc:oracle:thin:@//db-server:1521/xe
export REFERENCE_API_URL=http://reference-service:8080

# Centralized Logging (k-log-tx)
export LOGGING_CENTRALIZED_ENABLED=true
export LOGGING_DATASOURCE_URL=jdbc:oracle:thin:@//db-server:1521/xe
export LOGGING_CORRELATION_HEADER=MessageId

```

## Troubleshooting

### Common Issues

1. **MQ Connection Failures**

   - Check MQ server availability and credentials
   - Verify queue names and permissions

2. **Kafka Publishing Errors** (CFT Messages)

   - Validate Kafka broker connectivity
   - Check topic existence and permissions
   - Verify `k-kafka-message-receiver` is consuming messages

3. **ğŸ†• Processing Module Integration Issues** (HTTP/MQ Messages)

   - Verify processing module is deployed and running
   - Check `direct:kafka-message-processing` endpoint availability
   - Monitor processing module logs for connection errors
   - Validate `ingestion.processing.enabled=true` configuration

4. **Validation Failures**

   - Review message format and structure
   - Check validation rules and strictness settings

5. **ğŸ†• Routing Decision Problems**

   - Check `ReceiptChannel` header is set correctly (MQ/HTTP/CFT)
   - Review routing logs for decision tracking
   - Verify both Kafka and processing routes are configured

6. **ğŸ†• CDM Processing Issues**

   - Verify JSON payload format matches expected CDM schema
   - Check `CdmMessage` entity mapping and database table structure
   - Review CDM field extraction logs for parsing errors
   - Validate CDM type detection and routing logic
   - **ğŸ†• CDM Processing Issues**: Verify processing module is handling CDM persistence correctly
   - **ğŸ†• CDM Persistence Failures**: Check `k-db-tx` kamelet is available for CDM mode

7. **Performance Issues**

   - Monitor memory usage and GC
   - Check Kafka producer/consumer configurations (CFT route)
   - **ğŸ†• Monitor processing module performance** (HTTP/MQ route)
   - Review batch processing settings
   - **ğŸ†• Compare latency between Kafka and direct processing routes**
   - **ğŸ†• Monitor CDM vs MESSAGE processing performance**
   - **ğŸ†• Check k-log-tx performance impact and async processing configuration**

8. **ğŸ†• Centralized Logging Issues**
   - Verify `k-log-tx` kamelet is deployed and accessible
   - Check database connectivity for log persistence
   - Monitor log table growth and retention policies
   - Validate correlation ID consistency across log entries
   - Check async logging performance under high load

### ğŸ†• Routing Troubleshooting

#### Verify Routing Configuration

```bash
# Check if processing module integration is enabled
grep "ingestion.processing.enabled" application.properties

# Verify endpoint configuration
grep "ingestion.processing.endpoint" application.properties

# Check routing decision logs
grep "Routing message based on receipt channel" logs/ingestion.log
```

#### Test Routing Paths

```bash
# Test HTTP route (should go to processing module)
curl -X POST http://localhost:8080/ingestion/api/v1/payments \
  -H "Content-Type: application/json" \
  -d '{"messageType":"pacs.008","payload":"<xml>test</xml>"}'

# Monitor CFT route (should go to Kafka)
tail -f logs/ingestion.log | grep "CFT message - routing to Kafka"

# Monitor HTTP/MQ route (should go to processing)
tail -f logs/ingestion.log | grep "HTTP/MQ message - routing to processing module"
```

### Log Analysis

```bash
# Follow application logs
tail -f logs/ingestion.log

# Search for errors
grep "ERROR" logs/ingestion.log

# Monitor specific route
grep "payment-ingestion-orchestrator" logs/ingestion.log

# Monitor centralized logging activity
grep "k-log-tx" logs/ingestion.log

# Check correlation tracking
grep "MessageId: MSG123" logs/ingestion.log
```

### ğŸ†• Centralized Log Database Queries

```sql
-- Query all logs for a specific message
SELECT * FROM log_entry
WHERE correlation_id = 'MSG123'
ORDER BY created_at;

-- Monitor error patterns
SELECT log_source, COUNT(*) as error_count
FROM log_entry
WHERE log_level = 'ERROR'
  AND created_at >= SYSDATE - 1
GROUP BY log_source;

-- Performance analysis by route
SELECT log_source, log_category, AVG(processing_time) as avg_time
FROM log_entry
WHERE log_category = 'BUSINESS'
  AND created_at >= SYSDATE - 1
GROUP BY log_source, log_category;

-- Business intelligence queries
SELECT
  DATE_TRUNC('hour', created_at) as hour,
  COUNT(*) as message_count,
  COUNT(CASE WHEN log_level = 'ERROR' THEN 1 END) as error_count
FROM log_entry
WHERE log_category = 'BUSINESS'
GROUP BY DATE_TRUNC('hour', created_at)
ORDER BY hour;
```
