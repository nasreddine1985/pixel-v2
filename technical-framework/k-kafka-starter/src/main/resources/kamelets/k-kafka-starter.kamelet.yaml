apiVersion: camel.apache.org/v1
kind: Kamelet
metadata:
  name: k-kafka-starter
  labels:
    camel.apache.org/kamelet.type: "source"
    camel.apache.org/kamelet.group: "Kafka"
    camel.apache.org/provider: "Pixel"
  annotations:
    camel.apache.org/kamelet.support.level: "Stable"
    camel.apache.org/catalog.version: "4.1.0"
    camel.apache.org/provider: "Pixel V2"
spec:
  definition:
    title: "Kafka Starter"
    description: "Starts Kafka message consumption and routes them for processing"
    required:
      - bootstrapServers
      - topic
    type: object
    properties:
      bootstrapServers:
        title: Bootstrap Servers
        description: Comma-separated list of Kafka bootstrap servers
        type: string
        example: "localhost:9092"
      topic:
        title: Topic Name
        description: Name of the Kafka topic to consume from
        type: string
        example: "payment-events"
      groupId:
        title: Consumer Group ID
        description: Kafka consumer group identifier
        type: string
        example: "payment-processor-group"
        default: "k-kafka-receiver-group"
      offsetReset:
        title: Offset Reset Strategy
        description: What to do when there is no initial offset in Kafka
        type: string
        enum: ["earliest", "latest"]
        default: "latest"
      maxPollRecords:
        title: Max Poll Records
        description: Maximum number of records returned in a single call to poll()
        type: integer
        default: 500
      sessionTimeoutMs:
        title: Session Timeout
        description: Timeout used to detect client failures when using Kafka's group management facility
        type: integer
        default: 30000

      autoCommitIntervalMs:
        title: Auto Commit Interval
        description: Frequency in milliseconds that the consumer offsets are auto-committed to Kafka
        type: integer
        default: 5000
      valueDeserializer:
        title: Value Deserializer
        description: Deserializer class for values
        type: string
        default: "org.apache.kafka.common.serialization.StringDeserializer"
      keyDeserializer:
        title: Key Deserializer
        description: Deserializer class for keys
        type: string
        default: "org.apache.kafka.common.serialization.StringDeserializer"
      sinkEndpoint:
        title: Sink Endpoint
        description: Endpoint to route consumed messages to
        type: string
        example: "direct:kafka-message-processing"
        default: "direct:kafka-message-processing"
  dependencies:
    - "camel:kafka"
    - "camel:log"
    - "camel:direct"
    - "camel:jackson"
  template:
    from:
      uri: "kafka:{{topic}}"
      parameters:
        brokers: "{{bootstrapServers}}"
        groupId: "{{groupId}}"
        autoOffsetReset: "{{offsetReset}}"
        maxPollRecords: "{{maxPollRecords}}"
        sessionTimeoutMs: "{{sessionTimeoutMs}}"
        autoCommitIntervalMs: "{{autoCommitIntervalMs}}"
        valueDeserializer: "{{valueDeserializer}}"
        keyDeserializer: "{{keyDeserializer}}"
      steps:
        - log:
            loggingLevel: INFO
            message: "[KAFKA-STARTER] Received message from topic '{{topic}}' with key: ${header.KafkaKey}, partition: ${header.KafkaPartition}, offset: ${header.KafkaOffset}"
        - setHeader:
            name: MessageSource
            constant: "KAFKA_TOPIC"
        - setHeader:
            name: ReceiptTimestamp
            simple: "${date:now:yyyy-MM-dd'T'HH:mm:ss.SSS}"
        - setHeader:
            name: ReceiptChannel
            constant: "KAFKA_CONSUMER"
        - setHeader:
            name: KafkaTopic
            simple: "{{topic}}"
        - setHeader:
            name: KafkaGroupId
            simple: "{{groupId}}"
        - setHeader:
            name: KafkaPartition
            simple: "${header.KafkaPartition}"
        - setHeader:
            name: KafkaOffset
            simple: "${header.KafkaOffset}"
        - setHeader:
            name: KafkaKey
            simple: "${header.KafkaKey}"
        - setHeader:
            name: KafkaTimestamp
            simple: "${header.KafkaTimestamp}"
        - log:
            loggingLevel: INFO
            message: "[KAFKA-STARTER] Message enriched with Kafka metadata, routing to: {{sinkEndpoint}}"
        - to: "{{sinkEndpoint}}"