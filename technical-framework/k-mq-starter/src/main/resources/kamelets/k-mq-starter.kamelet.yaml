apiVersion: camel.apache.org/v1alpha1
kind: Kamelet
metadata:
  name: k-mq-starter
  labels:
    camel.apache.org/kamelet.type: "source"
spec:
  definition:
    title: "K-MQ Starter"
    description: |-
      JMS Queue listener that processes messages
    required:
      - mqFileName
      - connectionFactory
      - nasArchiveUrl
      - dataSource
    type: object
    properties:
      mqFileName:
        title: MQ File Name
        description: Name of the JMS queue to listen to
        type: string
      connectionFactory:
        title: Connection Factory
        description: JMS connection factory bean name
        type: string
        default: "jmsConnectionFactory"
      concurrentConsumers:
        title: Concurrent Consumers
        description: Number of concurrent consumers
        type: integer
        default: 1
      flowCode:
        title: Flow Code
        description: Flow processing code
        type: string
      brokers:
        title: Kafka Brokers
        description: Kafka brokers for flow summary
        type: string
      dataSource:
        title: Data Source
        description: Database data source bean name for sequence generation
        type: string
        default: "dataSource"
      nasArchiveUrl:
        title: NAS Archive URL
        description: File URL for archiving messages to NAS (mounted directory)
        type: string
  dependencies:
    - "camel:jms"
    - "camel:sql"
    - "camel:file"
    - "camel:kamelet"
  template:
    from:
      uri: "jms:queue:{{mqFileName}}?connectionFactory=#{{connectionFactory}}&concurrentConsumers={{concurrentConsumers}}"
      steps:
        # - log:
        #     message: "[K-MQ-STARTER] - Message received from queue: {{mqFileName}}, MessageId: ${header.JMSMessageID}, CorrelationId: ${header.JMSCorrelationID}"
        
        - setHeader:
            name: "MessageId"
            simple: "${header.JMSMessageID}"
        - setHeader:
            name: "CorrelationId"
            simple: "${header.JMSCorrelationID}"
        - setHeader:
            name: "MqFileName"
            simple: "{{mqFileName}}"
        - setHeader:
            name: "FlowCode"
            simple: "{{flowCode}}"
        - setHeader:
            name: "ConnectionFactory"
            simple: "{{connectionFactory}}"
        - setHeader:
            name: "NasArchiveUrl"
            simple: "{{nasArchiveUrl}}"
        - setHeader:
            name: "DataSource"
            simple: "{{dataSource}}"
        - setHeader:
            name: "Brokers"
            constant: "{{brokers}}"
        - setHeader:
            name: "KafkaFlowSummaryTopicName"
            simple: "{{flowCode}}-flow-summary-topic"
        - setHeader:
            name: "KafkaLogTopicName"
            simple: "{{flowCode}}-log-event-topic"
        - setHeader:
            name: "KafkaDistributionTopicName"
            simple: "{{flowCode}}-distribution-topic"
        

        # Store original body before sequence generation
        - setHeader:
            name: "OriginalBody"
            simple: "${body}"
        # Generate unique flow occurrence ID from database sequence
        - doTry:
            steps:
              - to:
                  uri: "sql:SELECT nextval('pixel_v2.flow_occurence_id_seq') as flowOccurId?dataSource=#dataSource"
              - setHeader:
                  name: "FlowOccurId"
                  simple: "${body[0][flowOccurId]}"
              - setHeader:
                  name: "Level"
                  simple: "INFO"
            doCatch:
              - exception: "java.lang.Exception"
                steps:
                  - log:
                      message: "Database sequence failed, generating UUID fallback: ${exception.message}"
                      loggingLevel: WARN
                  - setHeader:
                      name: "Level"
                      simple: "ERROR"
                  - setHeader:
                      name: "FlowOccurId"
                      simple: "${bean:uuidGenerator.generateUuid}"
        - setHeader:
            name: "ProcessingTimestamp"
            simple: "${date:now:yyyy-MM-dd'T'HH:mm:ss.SSSSSS}"
        - setHeader:
            name: "ContextId"
            simple: "mq-starter-2-${uuid}"

        # Restore original body
        - setBody:
            simple: "${header.OriginalBody}"
        - removeHeader:
            name: "OriginalBody"
        # Log event before starting MQ processing
        - toD:
            uri: "kamelet:k-log-events?flowId=${header.FlowOccurId}&flowCode=${header.FlowCode}&kafkaTopicName=${header.KafkaLogTopicName}&brokers=${header.Brokers}&logMessageTxt=Start MQ processing - queue: ${header.MqFileName}, MessageId: ${header.MessageId}&level=${header.Level}&processingTimestamp=${header.ProcessingTimestamp}&contextId=${header.ContextId}"
            pattern: "InOnly"
        - setHeader:
            name: "Step"
            constant: "IN_PROGRESS"
        # Set charset with proper fallback
        - choice:
            when:
              - simple: "${header.JMS_IBM_CHARACTER_SET} != null && ${header.JMS_IBM_CHARACTER_SET} != ''"
                steps:
                  - setHeader:
                      name: "JMSEncoding" 
                      simple: "${header.JMS_IBM_CHARACTER_SET}"
            otherwise:
              steps:
                - setHeader:
                    name: "JMSEncoding"
                    constant: "utf-8"
        
        - setHeader:
            name: "OriginalBody"
            simple: "${body}"
        - toD:
            uri: "${header.NasArchiveUrl}/IN/${header.FlowOccurId}/?fileName=${header.FlowCode}_${header.FlowOccurId}_${date:now:yyyyMMddHHmmssSSS}.txt&autoCreate=true&tempPrefix=.tmp"
        # Restore original body after file operation
        - setBody:
            simple: "${header.OriginalBody}"
        - removeHeader:
            name: "OriginalBody"
        - setHeader:
            name: "ProcessingTimestamp"
            simple: "${date:now:yyyy-MM-dd'T'HH:mm:ss.SSSSSS}"
        - wireTap:
            uri: "kamelet:k-log-flow-summary?step=${header.Step}&kafkaTopicName=${header.KafkaFlowSummaryTopicName}&brokers=${header.Brokers}"
        
        # Log event after completing MQ processing
        - toD:
            uri: "kamelet:k-log-events?flowId=${header.FlowOccurId}&flowCode=${header.FlowCode}&kafkaTopicName=${header.KafkaLogTopicName}&brokers=${header.Brokers}&logMessageTxt=End MQ processing - queue: ${header.MqFileName}, flowOccurId: ${header.FlowOccurId}, archived to: ${header.NasArchiveUrl}/IN/${header.FlowOccurId}/&level=INFO&processingTimestamp=${header.ProcessingTimestamp}&contextId=${header.ContextId}"
            pattern: "InOnly"
        - to: "kamelet:sink"